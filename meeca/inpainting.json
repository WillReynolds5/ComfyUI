{
    "75": {
      "inputs": {
        "samples": [
          "81",
          0
        ],
        "vae": [
          "76",
          2
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "76": {
      "inputs": {
        "ckpt_name": "lustifySDXLNSFW_v40.safetensors"
      },
      "class_type": "CheckpointLoaderSimple",
      "_meta": {
        "title": "Load Checkpoint"
      }
    },
    "77": {
      "inputs": {
        "image": "2f3080e7b426eb01a8959bf3a81ae388d261e4cf343e7f764bcc9f7f.jpg",
        "upload": "image"
      },
      "class_type": "LoadImage",
      "_meta": {
        "title": "Load Image"
      }
    },
    "78": {
      "inputs": {
        "filename_prefix": "comfyui",
        "images": [
          "75",
          0
        ]
      },
      "class_type": "SaveImage",
      "_meta": {
        "title": "Save Image"
      }
    },
    "79": {
      "inputs": {
        "text": "beautiful women wearing hat, hold cigarette",
        "clip": [
          "76",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Prompt)"
      }
    },
    "80": {
      "inputs": {
        "text": "mutliple women",
        "clip": [
          "76",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Prompt)"
      }
    },
    "81": {
      "inputs": {
        "seed": 673119787479667,
        "steps": 5,
        "cfg": 2,
        "sampler_name": "dpmpp_sde_gpu",
        "scheduler": "karras",
        "denoise": 1,
        "model": [
          "76",
          0
        ],
        "positive": [
          "84",
          0
        ],
        "negative": [
          "84",
          1
        ],
        "latent_image": [
          "82",
          0
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "82": {
      "inputs": {
        "grow_mask_by": 6,
        "pixels": [
          "77",
          0
        ],
        "vae": [
          "76",
          2
        ],
        "mask": [
          "87",
          0
        ]
      },
      "class_type": "VAEEncodeForInpaint",
      "_meta": {
        "title": "VAE Encode (for Inpainting)"
      }
    },
    "83": {
      "inputs": {
        "control_net_name": "depth/control-depth.safetensors"
      },
      "class_type": "ControlNetLoader",
      "_meta": {
        "title": "Load ControlNet Model"
      }
    },
    "84": {
      "inputs": {
        "strength": 0.85,
        "start_percent": 0,
        "end_percent": 1,
        "positive": [
          "79",
          0
        ],
        "negative": [
          "80",
          0
        ],
        "control_net": [
          "83",
          0
        ],
        "image": [
          "88",
          0
        ],
        "vae": [
          "76",
          2
        ]
      },
      "class_type": "ControlNetApplyAdvanced",
      "_meta": {
        "title": "Apply ControlNet"
      }
    },
    "86": {
      "inputs": {
        "image": "c3522433bfca79df897ea1b968d3c01571287881a8f66bb09dca9ca7.png",
        "channel": "alpha",
        "upload": "image"
      },
      "class_type": "LoadImageMask",
      "_meta": {
        "title": "Load Image (as Mask)"
      }
    },
    "87": {
      "inputs": {
        "mask": [
          "86",
          0
        ]
      },
      "class_type": "InvertMask",
      "_meta": {
        "title": "InvertMask"
      }
    },
    "88": {
      "inputs": {
        "da_model": [
          "90",
          0
        ],
        "images": [
          "77",
          0
        ]
      },
      "class_type": "DepthAnything_V2",
      "_meta": {
        "title": "Depth Anything V2"
      }
    },
    "90": {
      "inputs": {
        "model": "depth_anything_v2_vitl_fp32.safetensors"
      },
      "class_type": "DownloadAndLoadDepthAnythingV2Model",
      "_meta": {
        "title": "DownloadAndLoadDepthAnythingV2Model"
      }
    }
  }